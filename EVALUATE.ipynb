{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "logs_base_dir = \"./logs\"\n",
    "logdir = os.path.join(logs_base_dir, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "chk_base_dir = \"./checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard.notebook\n",
    "%tensorboard --logdir {logs_base_dir}\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Massage data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_data(_df):\n",
    "    df=_df\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "def feature_eng(_df):\n",
    "    df=_df\n",
    "    df['avg_CC_1hop'] = df['sum_1hop_current_charge']/df['size_1hop']\n",
    "    df['avg_CC_2hop'] = df['sum_2hop_current_charge']/df['size_2hop']\n",
    "    df['avg_CC_3hop'] = df['sum_3hop_current_charge']/df['size_3hop']\n",
    "    df['avg_EF_1hop'] = df['sum_1hop_energy_fraction']/df['size_1hop']\n",
    "    df['avg_EF_2hop'] = df['sum_2hop_energy_fraction']/df['size_2hop']\n",
    "    df['avg_EF_3hop'] = df['sum_3hop_energy_fraction']/df['size_3hop']\n",
    "    df = df.drop([\n",
    "        'sum_1hop_current_charge', \n",
    "        'sum_2hop_current_charge', \n",
    "        'sum_3hop_current_charge',\n",
    "        'sum_1hop_energy_fraction',\n",
    "        'sum_2hop_energy_fraction',\n",
    "        'sum_3hop_energy_fraction',\n",
    "        'sum_1hop_flow_counter',\n",
    "        'sum_2hop_flow_counter',\n",
    "        'sum_3hop_flow_counter',\n",
    "        'sum_1hop_initial_charge',\n",
    "        'sum_2hop_initial_charge',\n",
    "        'sum_3hop_initial_charge'\n",
    "    ], axis='columns')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data\n",
    "X_test = feature_eng(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = to_categorical(X_test['label_energy_fraction'].values)\n",
    "X_test = X_test.drop(['label_current_charge', 'label_energy_fraction', 'label_flow_count', 'label_initial_charge'], axis='columns')\n",
    "\n",
    "le = LabelEncoder()\n",
    "X_test['frame_type'] = le.fit_transform(X_test['frame_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a short sequential model\n",
    "def create_model(sample_input): # numpy array so we can use .shape\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(64, activation='relu', input_shape=sample_input.shape),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(9, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # from my initial tests\n",
    "    model.compile(optimizer=tf.train.RMSPropOptimizer(0.01),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    # from another tf.keras tutorial\n",
    "#     model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "#                 loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "#                 metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on unseen data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 hops neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(X_test.values[0])\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(chk_base_dir,'3hops'))\n",
    "loss,acc = model.evaluate(X_test, y_test)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 hops neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop(['size_3hop', 'avg_CC_3hop', 'avg_EF_3hop'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(X_test.values[0])\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(chk_base_dir,'2hops'))\n",
    "loss,acc = model.evaluate(X_test, y_test)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 hop neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.drop(['size_2hop', 'avg_CC_2hop', 'avg_EF_2hop'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(X_test.values[0])\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(chk_base_dir,'1hop'))\n",
    "loss,acc = model.evaluate(X_test, y_test)\n",
    "print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
