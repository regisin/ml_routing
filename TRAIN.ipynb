{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "logs_base_dir = \"./logs\"\n",
    "logdir = os.path.join(logs_base_dir, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "chk_base_dir = \"./checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0d0d4bc278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard.notebook\n",
    "%tensorboard --logdir {logs_base_dir}\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_size</th>\n",
       "      <th>frame_type</th>\n",
       "      <th>label_current_charge</th>\n",
       "      <th>label_energy_fraction</th>\n",
       "      <th>label_flow_count</th>\n",
       "      <th>label_initial_charge</th>\n",
       "      <th>size_1hop</th>\n",
       "      <th>size_2hop</th>\n",
       "      <th>size_3hop</th>\n",
       "      <th>sum_1hop_current_charge</th>\n",
       "      <th>...</th>\n",
       "      <th>sum_1hop_flow_counter</th>\n",
       "      <th>sum_1hop_initial_charge</th>\n",
       "      <th>sum_2hop_current_charge</th>\n",
       "      <th>sum_2hop_energy_fraction</th>\n",
       "      <th>sum_2hop_flow_counter</th>\n",
       "      <th>sum_2hop_initial_charge</th>\n",
       "      <th>sum_3hop_current_charge</th>\n",
       "      <th>sum_3hop_energy_fraction</th>\n",
       "      <th>sum_3hop_flow_counter</th>\n",
       "      <th>sum_3hop_initial_charge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534.0</td>\n",
       "      <td>I</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>534.0</td>\n",
       "      <td>I</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>534.0</td>\n",
       "      <td>I</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>534.0</td>\n",
       "      <td>I</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>534.0</td>\n",
       "      <td>I</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   frame_size frame_type  label_current_charge  label_energy_fraction  \\\n",
       "0       534.0          I              0.500000               0.500000   \n",
       "1       534.0          I              0.666667               0.666667   \n",
       "2       534.0          I              0.666667               0.666667   \n",
       "3       534.0          I              0.000000               0.000000   \n",
       "4       534.0          I              0.333333               0.333333   \n",
       "\n",
       "   label_flow_count  label_initial_charge  size_1hop  size_2hop  size_3hop  \\\n",
       "0          0.500000              0.500000        2.0        3.0        4.0   \n",
       "1          0.666667              0.666667        3.0        4.0        5.0   \n",
       "2          0.666667              0.666667        3.0        5.0        6.0   \n",
       "3          0.000000              0.000000        3.0        5.0        7.0   \n",
       "4          0.333333              0.333333        3.0        5.0        6.0   \n",
       "\n",
       "   sum_1hop_current_charge  ...  sum_1hop_flow_counter  \\\n",
       "0                    200.0  ...                    0.0   \n",
       "1                    300.0  ...                    0.0   \n",
       "2                    300.0  ...                    0.0   \n",
       "3                    300.0  ...                    0.0   \n",
       "4                    300.0  ...                    0.0   \n",
       "\n",
       "   sum_1hop_initial_charge  sum_2hop_current_charge  sum_2hop_energy_fraction  \\\n",
       "0                    200.0                    300.0                       3.0   \n",
       "1                    300.0                    400.0                       4.0   \n",
       "2                    300.0                    500.0                       5.0   \n",
       "3                    300.0                    500.0                       5.0   \n",
       "4                    300.0                    500.0                       5.0   \n",
       "\n",
       "   sum_2hop_flow_counter  sum_2hop_initial_charge  sum_3hop_current_charge  \\\n",
       "0                    0.0                    300.0                    400.0   \n",
       "1                    0.0                    400.0                    500.0   \n",
       "2                    0.0                    500.0                    600.0   \n",
       "3                    0.0                    500.0                    700.0   \n",
       "4                    0.0                    500.0                    600.0   \n",
       "\n",
       "   sum_3hop_energy_fraction  sum_3hop_flow_counter  sum_3hop_initial_charge  \n",
       "0                       4.0                    0.0                    400.0  \n",
       "1                       5.0                    0.0                    500.0  \n",
       "2                       6.0                    0.0                    600.0  \n",
       "3                       7.0                    0.0                    700.0  \n",
       "4                       6.0                    0.0                    600.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('train_data.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_size</th>\n",
       "      <th>label_current_charge</th>\n",
       "      <th>label_energy_fraction</th>\n",
       "      <th>label_flow_count</th>\n",
       "      <th>label_initial_charge</th>\n",
       "      <th>size_1hop</th>\n",
       "      <th>size_2hop</th>\n",
       "      <th>size_3hop</th>\n",
       "      <th>sum_1hop_current_charge</th>\n",
       "      <th>sum_1hop_energy_fraction</th>\n",
       "      <th>sum_1hop_flow_counter</th>\n",
       "      <th>sum_1hop_initial_charge</th>\n",
       "      <th>sum_2hop_current_charge</th>\n",
       "      <th>sum_2hop_energy_fraction</th>\n",
       "      <th>sum_2hop_flow_counter</th>\n",
       "      <th>sum_2hop_initial_charge</th>\n",
       "      <th>sum_3hop_current_charge</th>\n",
       "      <th>sum_3hop_energy_fraction</th>\n",
       "      <th>sum_3hop_flow_counter</th>\n",
       "      <th>sum_3hop_initial_charge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>232028.000000</td>\n",
       "      <td>232028.000000</td>\n",
       "      <td>232028.000000</td>\n",
       "      <td>232028.000000</td>\n",
       "      <td>232028.000000</td>\n",
       "      <td>232028.000000</td>\n",
       "      <td>232028.000000</td>\n",
       "      <td>232028.000000</td>\n",
       "      <td>232028.000000</td>\n",
       "      <td>232028.000000</td>\n",
       "      <td>232028.000000</td>\n",
       "      <td>232028.000000</td>\n",
       "      <td>232028.000000</td>\n",
       "      <td>232028.000000</td>\n",
       "      <td>232028.000000</td>\n",
       "      <td>232028.000000</td>\n",
       "      <td>232028.000000</td>\n",
       "      <td>232028.000000</td>\n",
       "      <td>232028.000000</td>\n",
       "      <td>232028.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3242.410287</td>\n",
       "      <td>0.322316</td>\n",
       "      <td>0.365025</td>\n",
       "      <td>0.342098</td>\n",
       "      <td>0.409756</td>\n",
       "      <td>3.459656</td>\n",
       "      <td>5.787099</td>\n",
       "      <td>7.080913</td>\n",
       "      <td>238.451401</td>\n",
       "      <td>2.384514</td>\n",
       "      <td>1242.376765</td>\n",
       "      <td>345.965573</td>\n",
       "      <td>401.758627</td>\n",
       "      <td>4.017586</td>\n",
       "      <td>1846.454880</td>\n",
       "      <td>578.709897</td>\n",
       "      <td>493.213167</td>\n",
       "      <td>4.932132</td>\n",
       "      <td>2186.060924</td>\n",
       "      <td>708.091265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2308.661053</td>\n",
       "      <td>0.261609</td>\n",
       "      <td>0.262120</td>\n",
       "      <td>0.262144</td>\n",
       "      <td>0.277355</td>\n",
       "      <td>0.623100</td>\n",
       "      <td>1.547656</td>\n",
       "      <td>2.043541</td>\n",
       "      <td>84.890789</td>\n",
       "      <td>0.848908</td>\n",
       "      <td>910.456039</td>\n",
       "      <td>62.310006</td>\n",
       "      <td>161.979522</td>\n",
       "      <td>1.619795</td>\n",
       "      <td>1407.325823</td>\n",
       "      <td>154.765567</td>\n",
       "      <td>204.363546</td>\n",
       "      <td>2.043635</td>\n",
       "      <td>1727.817889</td>\n",
       "      <td>204.354133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>72.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>53.054912</td>\n",
       "      <td>0.530549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>77.653072</td>\n",
       "      <td>0.776531</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>85.130272</td>\n",
       "      <td>0.851303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1405.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>173.731856</td>\n",
       "      <td>1.737319</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>277.339480</td>\n",
       "      <td>2.773395</td>\n",
       "      <td>757.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>339.690635</td>\n",
       "      <td>3.396906</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2746.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>232.636798</td>\n",
       "      <td>2.326368</td>\n",
       "      <td>1078.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>384.465644</td>\n",
       "      <td>3.844656</td>\n",
       "      <td>1553.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>463.263576</td>\n",
       "      <td>4.632636</td>\n",
       "      <td>1791.000000</td>\n",
       "      <td>600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4886.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>297.617296</td>\n",
       "      <td>2.976173</td>\n",
       "      <td>1768.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>499.204470</td>\n",
       "      <td>4.992045</td>\n",
       "      <td>2600.000000</td>\n",
       "      <td>700.000000</td>\n",
       "      <td>599.137162</td>\n",
       "      <td>5.991372</td>\n",
       "      <td>3033.000000</td>\n",
       "      <td>800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13169.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4882.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>799.980776</td>\n",
       "      <td>7.999808</td>\n",
       "      <td>8139.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>1199.858592</td>\n",
       "      <td>11.998586</td>\n",
       "      <td>10936.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          frame_size  label_current_charge  label_energy_fraction  \\\n",
       "count  232028.000000         232028.000000          232028.000000   \n",
       "mean     3242.410287              0.322316               0.365025   \n",
       "std      2308.661053              0.261609               0.262120   \n",
       "min        72.000000              0.000000               0.000000   \n",
       "25%      1405.000000              0.000000               0.250000   \n",
       "50%      2746.000000              0.333333               0.333333   \n",
       "75%      4886.000000              0.500000               0.666667   \n",
       "max     13169.000000              0.750000               0.750000   \n",
       "\n",
       "       label_flow_count  label_initial_charge      size_1hop      size_2hop  \\\n",
       "count     232028.000000         232028.000000  232028.000000  232028.000000   \n",
       "mean           0.342098              0.409756       3.459656       5.787099   \n",
       "std            0.262144              0.277355       0.623100       1.547656   \n",
       "min            0.000000              0.000000       2.000000       3.000000   \n",
       "25%            0.000000              0.250000       3.000000       5.000000   \n",
       "50%            0.333333              0.500000       4.000000       6.000000   \n",
       "75%            0.500000              0.666667       4.000000       7.000000   \n",
       "max            0.750000              0.750000       4.000000       8.000000   \n",
       "\n",
       "           size_3hop  sum_1hop_current_charge  sum_1hop_energy_fraction  \\\n",
       "count  232028.000000            232028.000000             232028.000000   \n",
       "mean        7.080913               238.451401                  2.384514   \n",
       "std         2.043541                84.890789                  0.848908   \n",
       "min         4.000000                53.054912                  0.530549   \n",
       "25%         6.000000               173.731856                  1.737319   \n",
       "50%         6.000000               232.636798                  2.326368   \n",
       "75%         8.000000               297.617296                  2.976173   \n",
       "max        12.000000               400.000000                  4.000000   \n",
       "\n",
       "       sum_1hop_flow_counter  sum_1hop_initial_charge  \\\n",
       "count          232028.000000            232028.000000   \n",
       "mean             1242.376765               345.965573   \n",
       "std               910.456039                62.310006   \n",
       "min                 0.000000               200.000000   \n",
       "25%               514.000000               300.000000   \n",
       "50%              1078.000000               400.000000   \n",
       "75%              1768.000000               400.000000   \n",
       "max              4882.000000               400.000000   \n",
       "\n",
       "       sum_2hop_current_charge  sum_2hop_energy_fraction  \\\n",
       "count            232028.000000             232028.000000   \n",
       "mean                401.758627                  4.017586   \n",
       "std                 161.979522                  1.619795   \n",
       "min                  77.653072                  0.776531   \n",
       "25%                 277.339480                  2.773395   \n",
       "50%                 384.465644                  3.844656   \n",
       "75%                 499.204470                  4.992045   \n",
       "max                 799.980776                  7.999808   \n",
       "\n",
       "       sum_2hop_flow_counter  sum_2hop_initial_charge  \\\n",
       "count          232028.000000            232028.000000   \n",
       "mean             1846.454880               578.709897   \n",
       "std              1407.325823               154.765567   \n",
       "min                 0.000000               300.000000   \n",
       "25%               757.000000               500.000000   \n",
       "50%              1553.000000               600.000000   \n",
       "75%              2600.000000               700.000000   \n",
       "max              8139.000000               800.000000   \n",
       "\n",
       "       sum_3hop_current_charge  sum_3hop_energy_fraction  \\\n",
       "count            232028.000000             232028.000000   \n",
       "mean                493.213167                  4.932132   \n",
       "std                 204.363546                  2.043635   \n",
       "min                  85.130272                  0.851303   \n",
       "25%                 339.690635                  3.396906   \n",
       "50%                 463.263576                  4.632636   \n",
       "75%                 599.137162                  5.991372   \n",
       "max                1199.858592                 11.998586   \n",
       "\n",
       "       sum_3hop_flow_counter  sum_3hop_initial_charge  \n",
       "count          232028.000000            232028.000000  \n",
       "mean             2186.060924               708.091265  \n",
       "std              1727.817889               204.354133  \n",
       "min                 0.000000               400.000000  \n",
       "25%               891.000000               600.000000  \n",
       "50%              1791.000000               600.000000  \n",
       "75%              3033.000000               800.000000  \n",
       "max             10936.000000              1200.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frame_size                  0\n",
       "frame_type                  0\n",
       "label_current_charge        0\n",
       "label_energy_fraction       0\n",
       "label_flow_count            0\n",
       "label_initial_charge        0\n",
       "size_1hop                   0\n",
       "size_2hop                   0\n",
       "size_3hop                   0\n",
       "sum_1hop_current_charge     0\n",
       "sum_1hop_energy_fraction    0\n",
       "sum_1hop_flow_counter       0\n",
       "sum_1hop_initial_charge     0\n",
       "sum_2hop_current_charge     0\n",
       "sum_2hop_energy_fraction    0\n",
       "sum_2hop_flow_counter       0\n",
       "sum_2hop_initial_charge     0\n",
       "sum_3hop_current_charge     0\n",
       "sum_3hop_energy_fraction    0\n",
       "sum_3hop_flow_counter       0\n",
       "sum_3hop_initial_charge     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0d0d322128>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data['label_energy_fraction'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0d0d272080>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data['label_current_charge'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_size</th>\n",
       "      <th>frame_type</th>\n",
       "      <th>label_current_charge</th>\n",
       "      <th>label_energy_fraction</th>\n",
       "      <th>label_flow_count</th>\n",
       "      <th>label_initial_charge</th>\n",
       "      <th>size_1hop</th>\n",
       "      <th>size_2hop</th>\n",
       "      <th>size_3hop</th>\n",
       "      <th>sum_1hop_current_charge</th>\n",
       "      <th>...</th>\n",
       "      <th>sum_1hop_flow_counter</th>\n",
       "      <th>sum_1hop_initial_charge</th>\n",
       "      <th>sum_2hop_current_charge</th>\n",
       "      <th>sum_2hop_energy_fraction</th>\n",
       "      <th>sum_2hop_flow_counter</th>\n",
       "      <th>sum_2hop_initial_charge</th>\n",
       "      <th>sum_3hop_current_charge</th>\n",
       "      <th>sum_3hop_energy_fraction</th>\n",
       "      <th>sum_3hop_flow_counter</th>\n",
       "      <th>sum_3hop_initial_charge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600.0</td>\n",
       "      <td>I</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>4350.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600.0</td>\n",
       "      <td>I</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>4650.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4650.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600.0</td>\n",
       "      <td>I</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>4350.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600.0</td>\n",
       "      <td>I</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>3150.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600.0</td>\n",
       "      <td>I</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>3900.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3900.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   frame_size frame_type  label_current_charge  label_energy_fraction  \\\n",
       "0       600.0          I              0.750000               0.750000   \n",
       "1       600.0          I              0.750000               0.750000   \n",
       "2       600.0          I              0.750000               0.750000   \n",
       "3       600.0          I              0.333333               0.333333   \n",
       "4       600.0          I              0.500000               0.500000   \n",
       "\n",
       "   label_flow_count  label_initial_charge  size_1hop  size_2hop  size_3hop  \\\n",
       "0          0.750000              0.750000        4.0       11.0       29.0   \n",
       "1          0.750000              0.750000        4.0       12.0       31.0   \n",
       "2          0.750000              0.750000        4.0       10.0       29.0   \n",
       "3          0.333333              0.333333        3.0        9.0       21.0   \n",
       "4          0.500000              0.500000        4.0        9.0       26.0   \n",
       "\n",
       "   sum_1hop_current_charge  ...  sum_1hop_flow_counter  \\\n",
       "0                    600.0  ...                    0.0   \n",
       "1                    600.0  ...                    0.0   \n",
       "2                    600.0  ...                    0.0   \n",
       "3                    450.0  ...                    0.0   \n",
       "4                    600.0  ...                    0.0   \n",
       "\n",
       "   sum_1hop_initial_charge  sum_2hop_current_charge  sum_2hop_energy_fraction  \\\n",
       "0                    600.0                   1650.0                      11.0   \n",
       "1                    600.0                   1800.0                      12.0   \n",
       "2                    600.0                   1500.0                      10.0   \n",
       "3                    450.0                   1350.0                       9.0   \n",
       "4                    600.0                   1350.0                       9.0   \n",
       "\n",
       "   sum_2hop_flow_counter  sum_2hop_initial_charge  sum_3hop_current_charge  \\\n",
       "0                    0.0                   1650.0                   4350.0   \n",
       "1                    0.0                   1800.0                   4650.0   \n",
       "2                    0.0                   1500.0                   4350.0   \n",
       "3                    0.0                   1350.0                   3150.0   \n",
       "4                    0.0                   1350.0                   3900.0   \n",
       "\n",
       "   sum_3hop_energy_fraction  sum_3hop_flow_counter  sum_3hop_initial_charge  \n",
       "0                      29.0                    0.0                   4350.0  \n",
       "1                      31.0                    0.0                   4650.0  \n",
       "2                      29.0                    0.0                   4350.0  \n",
       "3                      21.0                    0.0                   3150.0  \n",
       "4                      26.0                    0.0                   3900.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data = pd.read_csv('val_data.csv')\n",
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_size</th>\n",
       "      <th>label_current_charge</th>\n",
       "      <th>label_energy_fraction</th>\n",
       "      <th>label_flow_count</th>\n",
       "      <th>label_initial_charge</th>\n",
       "      <th>size_1hop</th>\n",
       "      <th>size_2hop</th>\n",
       "      <th>size_3hop</th>\n",
       "      <th>sum_1hop_current_charge</th>\n",
       "      <th>sum_1hop_energy_fraction</th>\n",
       "      <th>sum_1hop_flow_counter</th>\n",
       "      <th>sum_1hop_initial_charge</th>\n",
       "      <th>sum_2hop_current_charge</th>\n",
       "      <th>sum_2hop_energy_fraction</th>\n",
       "      <th>sum_2hop_flow_counter</th>\n",
       "      <th>sum_2hop_initial_charge</th>\n",
       "      <th>sum_3hop_current_charge</th>\n",
       "      <th>sum_3hop_energy_fraction</th>\n",
       "      <th>sum_3hop_flow_counter</th>\n",
       "      <th>sum_3hop_initial_charge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>66503.000000</td>\n",
       "      <td>66503.000000</td>\n",
       "      <td>66503.000000</td>\n",
       "      <td>66503.000000</td>\n",
       "      <td>66503.000000</td>\n",
       "      <td>66503.000000</td>\n",
       "      <td>66503.000000</td>\n",
       "      <td>66503.000000</td>\n",
       "      <td>66503.000000</td>\n",
       "      <td>66503.000000</td>\n",
       "      <td>66503.000000</td>\n",
       "      <td>66503.000000</td>\n",
       "      <td>66503.000000</td>\n",
       "      <td>66503.000000</td>\n",
       "      <td>66503.000000</td>\n",
       "      <td>66503.000000</td>\n",
       "      <td>66503.000000</td>\n",
       "      <td>66503.000000</td>\n",
       "      <td>66503.000000</td>\n",
       "      <td>66503.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2352.857300</td>\n",
       "      <td>0.399611</td>\n",
       "      <td>0.314622</td>\n",
       "      <td>0.456363</td>\n",
       "      <td>0.370483</td>\n",
       "      <td>3.604258</td>\n",
       "      <td>9.052223</td>\n",
       "      <td>22.659429</td>\n",
       "      <td>365.135957</td>\n",
       "      <td>2.434240</td>\n",
       "      <td>643.329790</td>\n",
       "      <td>540.638768</td>\n",
       "      <td>922.932048</td>\n",
       "      <td>6.152880</td>\n",
       "      <td>878.618423</td>\n",
       "      <td>1357.833481</td>\n",
       "      <td>2319.868500</td>\n",
       "      <td>15.465790</td>\n",
       "      <td>1352.229914</td>\n",
       "      <td>3398.914335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1435.839648</td>\n",
       "      <td>0.297595</td>\n",
       "      <td>0.288641</td>\n",
       "      <td>0.286660</td>\n",
       "      <td>0.276135</td>\n",
       "      <td>0.554602</td>\n",
       "      <td>1.790162</td>\n",
       "      <td>4.714443</td>\n",
       "      <td>129.206538</td>\n",
       "      <td>0.861377</td>\n",
       "      <td>817.737586</td>\n",
       "      <td>83.190227</td>\n",
       "      <td>343.057213</td>\n",
       "      <td>2.287048</td>\n",
       "      <td>873.045591</td>\n",
       "      <td>268.524300</td>\n",
       "      <td>866.962741</td>\n",
       "      <td>5.779752</td>\n",
       "      <td>1118.258722</td>\n",
       "      <td>707.166393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>134.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>38.257296</td>\n",
       "      <td>0.255049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>89.765040</td>\n",
       "      <td>0.598434</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>306.064496</td>\n",
       "      <td>2.040430</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1493.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>261.696899</td>\n",
       "      <td>1.744646</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>450.000000</td>\n",
       "      <td>652.727975</td>\n",
       "      <td>4.351520</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1636.390112</td>\n",
       "      <td>10.909267</td>\n",
       "      <td>488.500000</td>\n",
       "      <td>3000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2109.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>369.517606</td>\n",
       "      <td>2.463451</td>\n",
       "      <td>258.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>913.036313</td>\n",
       "      <td>6.086909</td>\n",
       "      <td>540.000000</td>\n",
       "      <td>1350.000000</td>\n",
       "      <td>2280.772190</td>\n",
       "      <td>15.205148</td>\n",
       "      <td>1070.000000</td>\n",
       "      <td>3450.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2828.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>460.781840</td>\n",
       "      <td>3.071879</td>\n",
       "      <td>934.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>1174.264846</td>\n",
       "      <td>7.828432</td>\n",
       "      <td>1380.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>2940.130367</td>\n",
       "      <td>19.600869</td>\n",
       "      <td>1985.000000</td>\n",
       "      <td>3900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9865.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4269.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>4868.000000</td>\n",
       "      <td>1800.000000</td>\n",
       "      <td>5245.467248</td>\n",
       "      <td>34.969782</td>\n",
       "      <td>8628.000000</td>\n",
       "      <td>5250.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         frame_size  label_current_charge  label_energy_fraction  \\\n",
       "count  66503.000000          66503.000000           66503.000000   \n",
       "mean    2352.857300              0.399611               0.314622   \n",
       "std     1435.839648              0.297595               0.288641   \n",
       "min      134.000000              0.000000               0.000000   \n",
       "25%     1493.000000              0.000000               0.000000   \n",
       "50%     2109.000000              0.500000               0.250000   \n",
       "75%     2828.000000              0.750000               0.666667   \n",
       "max     9865.000000              0.750000               0.750000   \n",
       "\n",
       "       label_flow_count  label_initial_charge     size_1hop     size_2hop  \\\n",
       "count      66503.000000          66503.000000  66503.000000  66503.000000   \n",
       "mean           0.456363              0.370483      3.604258      9.052223   \n",
       "std            0.286660              0.276135      0.554602      1.790162   \n",
       "min            0.000000              0.000000      2.000000      3.000000   \n",
       "25%            0.250000              0.000000      3.000000      8.000000   \n",
       "50%            0.500000              0.333333      4.000000      9.000000   \n",
       "75%            0.750000              0.666667      4.000000     10.000000   \n",
       "max            0.750000              0.750000      4.000000     12.000000   \n",
       "\n",
       "          size_3hop  sum_1hop_current_charge  sum_1hop_energy_fraction  \\\n",
       "count  66503.000000             66503.000000              66503.000000   \n",
       "mean      22.659429               365.135957                  2.434240   \n",
       "std        4.714443               129.206538                  0.861377   \n",
       "min        8.000000                38.257296                  0.255049   \n",
       "25%       20.000000               261.696899                  1.744646   \n",
       "50%       23.000000               369.517606                  2.463451   \n",
       "75%       26.000000               460.781840                  3.071879   \n",
       "max       35.000000               600.000000                  4.000000   \n",
       "\n",
       "       sum_1hop_flow_counter  sum_1hop_initial_charge  \\\n",
       "count           66503.000000             66503.000000   \n",
       "mean              643.329790               540.638768   \n",
       "std               817.737586                83.190227   \n",
       "min                 0.000000               300.000000   \n",
       "25%                73.000000               450.000000   \n",
       "50%               258.000000               600.000000   \n",
       "75%               934.000000               600.000000   \n",
       "max              4269.000000               600.000000   \n",
       "\n",
       "       sum_2hop_current_charge  sum_2hop_energy_fraction  \\\n",
       "count             66503.000000              66503.000000   \n",
       "mean                922.932048                  6.152880   \n",
       "std                 343.057213                  2.287048   \n",
       "min                  89.765040                  0.598434   \n",
       "25%                 652.727975                  4.351520   \n",
       "50%                 913.036313                  6.086909   \n",
       "75%                1174.264846                  7.828432   \n",
       "max                1800.000000                 12.000000   \n",
       "\n",
       "       sum_2hop_flow_counter  sum_2hop_initial_charge  \\\n",
       "count           66503.000000             66503.000000   \n",
       "mean              878.618423              1357.833481   \n",
       "std               873.045591               268.524300   \n",
       "min                 0.000000               450.000000   \n",
       "25%               198.000000              1200.000000   \n",
       "50%               540.000000              1350.000000   \n",
       "75%              1380.000000              1500.000000   \n",
       "max              4868.000000              1800.000000   \n",
       "\n",
       "       sum_3hop_current_charge  sum_3hop_energy_fraction  \\\n",
       "count             66503.000000              66503.000000   \n",
       "mean               2319.868500                 15.465790   \n",
       "std                 866.962741                  5.779752   \n",
       "min                 306.064496                  2.040430   \n",
       "25%                1636.390112                 10.909267   \n",
       "50%                2280.772190                 15.205148   \n",
       "75%                2940.130367                 19.600869   \n",
       "max                5245.467248                 34.969782   \n",
       "\n",
       "       sum_3hop_flow_counter  sum_3hop_initial_charge  \n",
       "count           66503.000000             66503.000000  \n",
       "mean             1352.229914              3398.914335  \n",
       "std              1118.258722               707.166393  \n",
       "min                 0.000000              1200.000000  \n",
       "25%               488.500000              3000.000000  \n",
       "50%              1070.000000              3450.000000  \n",
       "75%              1985.000000              3900.000000  \n",
       "max              8628.000000              5250.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frame_size                  0\n",
       "frame_type                  0\n",
       "label_current_charge        0\n",
       "label_energy_fraction       0\n",
       "label_flow_count            0\n",
       "label_initial_charge        0\n",
       "size_1hop                   0\n",
       "size_2hop                   0\n",
       "size_3hop                   0\n",
       "sum_1hop_current_charge     0\n",
       "sum_1hop_energy_fraction    0\n",
       "sum_1hop_flow_counter       0\n",
       "sum_1hop_initial_charge     0\n",
       "sum_2hop_current_charge     0\n",
       "sum_2hop_energy_fraction    0\n",
       "sum_2hop_flow_counter       0\n",
       "sum_2hop_initial_charge     0\n",
       "sum_3hop_current_charge     0\n",
       "sum_3hop_energy_fraction    0\n",
       "sum_3hop_flow_counter       0\n",
       "sum_3hop_initial_charge     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0d0b9d54a8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_data['label_energy_fraction'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0d0b98d780>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAFxCAYAAACLAiSOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGeZJREFUeJzt3X+w5XV93/HnvYssO+yCcLn+AFnoIPumXdfyI7SMgLZjksZJiElEgbAIoa0iGbGtdogWO05sDREypQhkiYkZBRpHzAhqBrfFKdUtSRohKz8c3wPaZS9oy+UidZdkV+Te/nG+Vy8bdu/5nHPu9/s9X56PmTN7zvdzvvd8PnvvOa/z/Xzf3+93YmFhAUmSSkw23QFJ0vgxPCRJxQwPSVIxw0OSVMzwkCQVMzwkScUMD0lSMcNDklTM8JAkFTM8JEnFDmq6AyO2Gjgd+D7wfMN9kaRxsQp4NfBXwN5+VuhaeJwOfL3pTkjSmDob2NbPE7sWHt8H+MEPnmV+vp4TPk5NrWVubnctr1W3Lo8NHN+4c3yjMzk5wRFHHArVZ2g/uhYezwPMzy/UFh6Lr9dVXR4bOL5x5/hGru/pfneYS5KKGR6SpGKGhySpmOEhSSpmeEiSihkekqRihockqZjhIUkq1rWDBAe27rA1HLJ6sP+O6el1xevs2ftjdv3wbwd6PUlqmuFROWT1QZzz/jtre70v/d5b2VXbq0nSaDltJUkqZnhIkooZHpKkYoaHJKmY4SFJKmZ4SJKK9VWqGxHXAm8Djgc2ZeZDEXE8cMeSp70cOCwzj6zW2QHsqW4AV2bm1qrtDOBmYA2wA9icmU8u1yZJaod+j/O4A/jPLLk+eGbuAE5efBwR173Izzs3Mx9auiAiJoFbgUsyc1tEXAVcDVx6oLaiUUmSVlRf01aZuS0zZ/bXHhEHAxcCn+rjx50G7MnMxYusbwHe0UebJKklRnWE+S8DT2Tm/fssvy0iJoBtwIcy8xlgPfDY4hMy86mImIyIIw/UlplP99uZqam1w4ylNoOc1mQQP3rueQ5+2aqB1h2kj8O8Xt3q+h00xfGNtzaPb1ThcSl/d6vj7MyciYjVwHXADcDmEb3eAc3N7S6+cHwTv6TZ2XpOUDI9va72U6/UNbZhTE+vG4t+Dsrxjbc6xzc5OVH8pXvoaquIOAZ4E3Db0uWL01yZuRe4CTizatoJHLdk/aOA+WrL4kBtkqSWGEWp7sXAn2Xm3OKCiDg0Ig6v7k8A5wPbq+b7gDURcVb1+DLg9j7aJEkt0Vd4RMT1EfE48Brg7oh4eEnzJfzdKatXAvdExAPAQ8AG4HKAzJwHLgJ+PyIeobfV8lvLtUmS2qOvfR6ZeQVwxX7aNrzIsu8Cpxzg590LbCptkyS1g0eYS5KKGR6SpGKGhySpmOEhSSpmeEiSihkekqRihockqZjhIUkqZnhIkooZHpKkYoaHJKmY4SFJKmZ4SJKKGR6SpGKGhySpmOEhSSpmeEiSihkekqRihockqVhf1zCPiGuBtwHHA5sy86Fq+Q5gT3UDuDIzt1ZtZwA3A2uAHcDmzHxymDZJUjv0u+VxB/BG4LEXaTs3M0+ubovBMQncCvxmZm4AvgZcPUybJKk9+gqPzNyWmTMFP/c0YE9mbqsebwHeMWSbJKkl+pq2WsZtETEBbAM+lJnPAOtZspWSmU9FxGREHDloW2Y+3W+HpqbWDj+qGkxPr2u6CytmXMY2Lv0clOMbb20e37DhcXZmzkTEauA64AZg8/DdGs7c3G7m5xeK1mnilzQ7u6uW1+ny2IYxPb1uLPo5KMc33uoc3+TkRPGX7qGqrRansjJzL3ATcGbVtBM4bvF5EXEUMF9tPQzaJklqiYHDIyIOjYjDq/sTwPnA9qr5PmBNRJxVPb4MuH3INklSS/Rbqns98GvAq4C7I2IOOAf404hYBawCvgVcDpCZ8xFxEXBzRBxCVXI7TJskqT36Co/MvAK44kWaTjnAOvcCm0bZJklqB48wlyQVMzwkScUMD0lSMcNDklTM8JAkFTM8JEnFDA9JUjHDQ5JUzPCQJBUzPCRJxQwPSVIxw0OSVMzwkCQVMzwkScUMD0lSMcNDklTM8JAkFTM8JEnFDA9JUrG+rmEeEdcCbwOOBzZl5kMRMQXcApwA/Ah4BHh3Zs5W6ywADwLz1Y+5KDMfrNrOAa6pXv8+4Dcy82+Wa5MktUO/Wx53AG8EHluybAH4eGZGZm4CvgNcvc96b8jMk6vbYnCsBT4JnJOZrwV2AR9Yrk2S1B59hUdmbsvMmX2WPZ2Z9yxZ9BfAcX38uLcA38jMR6rHW4Dz+miTJLVEX9NWy4mISeA9wBf3abonIg4C7gI+kpl7gfW8cAtmJ3Bsdf9AbX2bmlpbukojpqfXNd2FFTMuYxuXfg7K8Y23No9vJOEBfALYDdywZNn6zJyJiMPo7Rv5MHDViF7vgObmdjM/v1C0ThO/pNnZXbW8TpfHNozp6XVj0c9BOb7xVuf4Jicnir90D11tVe1MPxE4LzMXd46zOM2VmT8E/hA4s2rayQunt9YDM320SZJaYqjwiIiPAacBv1JNSS0uPyIi1lT3DwLOBbZXzV8BTo+IE6vHlwGf66NNktQSfYVHRFwfEY8DrwHujoiHI2Ij8EHgaODeiNgeEV+oVjkJ+MuI+CbwAPAcvWkrMnMX8C7gyxHxKHA4cO1ybZKk9uhrn0dmXgFc8SJNE/t5/p8Drz/Az7sTuLO0TZLUDh5hLkkqZnhIkooZHpKkYoaHJKmY4SFJKmZ4SJKKGR6SpGKGhySpmOEhSSpmeEiSihkekqRihockqZjhIUkqZnhIkooZHpKkYoaHJKmY4SFJKmZ4SJKKGR6SpGLLXsM8Iq4F3gYcD2zKzIeq5RuATwNTwBzwzsx8ZKXaJEnt0c+Wxx3AG4HH9lm+BbgxMzcANwI3r3CbJKkllt3yyMxtABHxk2UR8QrgVODnqkV/AtwQEdPAxKjbMnN20AFKkkZv2fDYj2OBJzLzeYDMfD4ivlctn1iBtqLwmJpaO+Cw6jU9va7pLqyYcRnbuPRzUI5vvLV5fIOGR6vNze1mfn6haJ0mfkmzs7tqeZ0uj20Y09PrxqKfg3J8463O8U1OThR/6R602moGOCYiVgFU/x5dLV+JNklSiwwUHpn5JLAduKBadAHw15k5uxJtg/RRkrRy+inVvR74NeBVwN0RMZeZG4HLgE9HxL8HfgC8c8lqK9EmSWqJfqqtrgCueJHl3wb+8X7WGXmbJKk9PMJcklTM8JAkFTM8JEnFDA9JUjHDQ5JUzPCQJBUzPCRJxTp5biu9tKw7bA2HrB7sT3mQ837t2ftjdv3wbwd6PakrDA+NvUNWH8Q577+zttf70u+9le6ejk/qj9NWkqRihockqZjhIUkqZnhIkooZHpKkYoaHJKmY4SFJKmZ4SJKKGR6SpGKGhySp2FCnJ4mI44E7lix6OXBYZh4ZETuAPdUN4MrM3FqtdwZwM7AG2AFszswnl2uTJLXDUOGRmTuAkxcfR8R1+/zMczPzoaXrRMQkcCtwSWZui4irgKuBSw/UNkw/JUmjNbITI0bEwcCFwD9b5qmnAXsyc1v1eAu9LYxLl2mTXpI8a7DaaJRn1f1l4InMvH/JstsiYgLYBnwoM58B1gOPLT4hM5+KiMmIOPJAbZn5dL8dmZpaO+xYajHIG3tcdHlsUP/46j5r8CFj8vvz76w5owyPS4FPLXl8dmbORMRq4DrgBmDzCF9vv+bmdjM/v1C0ThO/pNnZek7s3eWxgeNbCXWOb1DT0+vGop+DqnN8k5MTxV+6R1JtFRHHAG8Cbltclpkz1b97gZuAM6umncBxS9Y9CpivtiwO1CZJaolRlepeDPxZZs4BRMShEXF4dX8COB/YXj33PmBNRJxVPb4MuL2PNklSS4xq2uoS4Iolj18J/GlErAJWAd8CLgfIzPmIuAi4OSIOoSrHXa5NUjdZEDCeRhIemblhn8ffBU45wPPvBTaVtknqHi8jPJ48wlySVGyU1VaSpH10dVrO8JCkFdTVaTmnrSRJxQwPSVIxw0OSVMzwkCQVMzwkScUMD0lSMcNDklTM8JAkFTM8JEnFDA9JUjHDQ5JUzPCQJBUzPCRJxQwPSVIxw0OSVMzwkCQVG/piUBGxA9hT3QCuzMytEXEGcDOwBtgBbM7MJ6t1BmqTJLXDqLY8zs3Mk6vb1oiYBG4FfjMzNwBfA64GGLRNktQeKzVtdRqwJzO3VY+3AO8Ysk2S1BKjuob5bRExAWwDPgSsBx5bbMzMpyJiMiKOHLQtM5/utzNTU2uHH1ENBrm4/bjo8tjA8Y07xze8UYTH2Zk5ExGrgeuAG4AvjODnDmxubjfz8wtF6zTxxzQ7W8dl6rs9NnB8K8Hxjc44jG9ycqL4S/fQ01aZOVP9uxe4CTgT2Akct/iciDgKmK+2HgZtkyS1xFDhERGHRsTh1f0J4HxgO3AfsCYizqqeehlwe3V/0DZJUksMu+XxSuCeiHgAeAjYAFyemfPARcDvR8QjwJuA3wIYtE2S1B5D7fPIzO8Cp+yn7V5g0yjbJEnt4BHmkqRihockqZjhIUkqZnhIkooZHpKkYoaHJKmY4SFJKmZ4SJKKGR6SpGKGhySpmOEhSSpmeEiSihkekqRihockqZjhIUkqZnhIkooZHpKkYoaHJKmY4SFJKjbUNcwjYgq4BTgB+BHwCPDuzJyNiAXgQWC+evpFmflgtd45wDXV698H/EZm/s1ybZKkdhh2y2MB+HhmRmZuAr4DXL2k/Q2ZeXJ1WwyOtcAngXMy87XALuADy7VJktpjqPDIzKcz854li/4COG6Z1d4CfCMzH6kebwHO66NNktQSQ01bLRURk8B7gC8uWXxPRBwE3AV8JDP3AuuBx5Y8ZydwbHX/QG19m5paW7pKI6an1zXdhRXT5bGB4xt3jm94IwsP4BPAbuCG6vH6zJyJiMPo7Rf5MHDVCF9vv+bmdjM/v1C0ThN/TLOzu2p5nS6PDRzfSnB8ozMO45ucnCj+0j2SaquIuBY4ETgvM+cBMnOm+veHwB8CZ1ZP38kLp7bWAzN9tEmSWmLo8IiIjwGnAb9STUsREUdExJrq/kHAucD2apWvAKdHxInV48uAz/XRJklqiaHCIyI2Ah8EjgbujYjtEfEF4CTgLyPim8ADwHP0pq3IzF3Au4AvR8SjwOHAtcu1SZLaY6h9Hpn5MDCxn+bXH2C9O4E7S9skSe3gEeaSpGKGhySpmOEhSSpmeEiSihkekqRihockqZjhIUkqZnhIkooZHpKkYoaHJKmY4SFJKmZ4SJKKGR6SpGKGhySpmOEhSSpmeEiSihkekqRihockqZjhIUkqNtQ1zFdKRGwAPg1MAXPAOzPzkWZ7JUla1NYtjy3AjZm5AbgRuLnh/kiSlmjdlkdEvAI4Ffi5atGfADdExHRmzi6z+iqAycmJgV77FUesGWi9QQ3az0F0eWzg+EbN8Y1W28e35Pmr+l1nYmFhoehFVlpEnAZ8JjM3Lln2LWBzZt6/zOpnAV9fyf5JUoedDWzr54mt2/IY0l/RG/z3gecb7oskjYtVwKvpfYb2pY3hMQMcExGrMvP5iFgFHF0tX85e+kxNSdILfKfkya3bYZ6ZTwLbgQuqRRcAf93H/g5JUk1at88DICJOoleqewTwA3qlutlsryRJi1oZHpKkdmvdtJUkqf0MD0lSMcNDklTM8JAkFTM8JEnFDA9JUrE2HmGuFoiII4DXAVkduNkpXR+fxldETACvAZ7IzPmm+7M/HudRICLWA28Hjq0WzQCfz8zHmuvVaETEJzLzvdX9M4A76Y3vOHonpdzaZP+G1fXxAUTE64CFzHw4Ik4Efgl4MDPvbrhrQ4uIaeD/ZeaPqsebgX8EfDMz/6jRzg0pIj6Ymb9T3T8J+AqwFvgxcE5m9n2+qTo5bdWniPjnwP8EjgeeqG7HA1+v2sbdmUvufwS4MDN/ht6p8X+7kR6NVqfHFxHvBb4MbI2I9wGfBTbQu5zB5Y12bjTuBlYDRMS/Ay6jF/5vj4hrmuzYCLx9yf2PAR/OzKOAi4Frm+nS8py26t+VwCmZ+dTShRHx28C9wFh/+9nHqxa/rWbm9ohY3XSHRqyL4/sXwEZ631j/N7AhMx+PiKOA/wbc1GTnRmAyM3dV938V+CeZuTsirgPuB/5tc10bqRMy8xaAzNwaEb/bdIf2x/Do3+S+wVF5Cqj3yjIr45iI+Di9sRy5eFbjqq0LW6hdH998Zj4LPBsR383MxwEy86mI6MLc9MKSC8I9C+wByMznqjNvj7PpautwAjh0n7bWfrYYHv3bGhF3AZ8EFvdxHAf8S+C/Ntar0Vn6zfSP6F0//smIOJreN7tx1/XxLQ3AD+7TdnCdHVkh/wH47xFxLfA14PMR8Xng54G7Gu3Z8O4GTq/ufz0iXp2Z36/+NltbzOEO8z5FxCRwIXAesL5avBO4HbilzVUR6r6IuIRe8cbufZafBLwrM/9NIx0boYj4GeBfAf+A3sWLdgL/BfhsZvpBVjPDQwBExC8BWzPzuab7UreIOLWPSxxLK6ba7zaVmd/bZ/nGzHy4oW4dUBfmehsXEac23YcRuBP4XkRcFxGvb7ozNfto0x0YhYh4XURsrO6fGBH/OiJ+tul+jUJETEfEwUseb46I67tQ6RgRPw/8H+BbEfGNiHjtkuZbGurWsgyP0ejCh88DwJvp7aD7avVHfHlEHN5wv0YqIqYi4uTqNgWQmb/YdL+GZanuWPuPwJsy8+XAJ4C7I+IfVm2t3WFueBTq6ocPvYPLHsjM99G7ZvzHgXOAxyPitma7NryIOCEivgo8CtxW3R6NiK/u801vXC2W6p4G/A7w1sx8D3AWvaKOcbdvqe4vZOY19P5Gf6G5bo3EyzLzAYDM/DS94zu+GBGnA63dr2B49Okl8OHzk284mflcZn4uM98C/H2glXOuhT4DfIrevPLGzNxIr+Lqj2nx1ECB+cx8NjP/L/CCUl1a/AFUYKE6yhz2KdWlt/N8nB0UEYcsPsjM/wGcD3weOKaxXi3D8Ohf1z98HnixhZn5eGZ+rO7OrICpzLxtaVVcZs5n5q3AEQ32a1ReKqW6l/DTUt3NEfEZxr9U97PA2UsXZOafA+fy08MCWsdqqz5FxLcz86TSNrVDRNxLbz75J2Wd1Qnofh14b2ae0WT/hmWprqW6dTM8+tT1D58D6UIpa3WiwC3AKfTOSwa9KYHtwHsyM5vqm7Q/bX7veYR5/y6m9+FzY0Ts++FzcWO9qsdHgbEuCsjMR4A3V/PmPzkrcnW6i07wrLqd1Nr3nlsehbr84QO9ajJeOL65Jvuj/lSluu+n94XwGuCdwP8C/ilwfWaO9YkRI+KbwFmZuasq1X0LvWOT3kwvIMf+xIjj9t4zPAT0qsmAPwBOBRaPcl0879O7M/PRpvqm5VUfrm9gP2fVzcxTGu3gkCLiwczcVN3/Bj89q+7LgPsX28bRuL73rLbSoq5Xk3Wdpbrjayzfe+7z0KKpzHzBwYBVWeutEXFVQ31S/14qpbpdPKvuWL733PLQoqcj4oKqggzoVZNFxIXAMw32S/35TxGxFiAzv7S4sCrVHftLBmTm54BLgJ+ltwP579E7w/VdwAea69lIjOV7z30eAixllZoyru89w0Mv0PVqsi6zVHe8jdt7z/CQOsBS3fEv1R037vOQusGz6qpWhofUDZbqqlaW6krdYKmuauWWh9QNluqqVu4wlyQVc9pK6ghLdVUnp62kDqhKdb8MbI2I99G7Ot0G4IaIuLzRzo3G3cBqgKpU9zJgBnh7RFzTZMdeqgwPqRss1VWtDA+pGyzVVa3c5yF1g6W6qpVbHlI3WKqrWlmqK0kq5rSV1BGW6qpOTltJHWCprupmeEjdYKmuamV4SN1gqa5q5T4PqRss1VWt3PKQusFSXdXKUl1JUjGnraSOsFRXdXLaSuoAS3VVN8ND6gZLdVUrw0PqBkt1VSv3eUjdYKmuauWWh9QNluqqVpbqSpKKOW0ldYSluqqT01ZSB1iqq7oZHlI3WKqrWhkeUjdYqqtauc9D6gZLdVUrtzykbrBUV7WyVFeSVMxpK6kjLNVVnZy2kjrAUl3VzfCQusFSXdXK8JC6wVJd1cp9HlI3WKqrWrnlIXWDpbqqlaW6kqRiTltJHWGprurktJXUAZbqqm6Gh9QNluqqVoaH1A2W6qpW7vOQusFSXdXKLQ+pGyzVVa0s1ZUkFXPaSuoIS3VVJ6etpA6wVFd1MzykbrBUV7UyPKRusFRXtXKfh9QNluqqVm55SN1gqa5qZamuJKmY01ZSR1iqqzo5bSV1gKW6qpvhIXWDpbqqleEhdYOluqqV+zykbrBUV7Vyy0PqBkt1VStLdSVJxZy2kjrCUl3VyWkrqQMs1VXdDA+pGyzVVa0MD6kbLNVVrdznIXWDpbqqlVseUjdYqqtaWaorSSrmtJXUEZbqqk5OW0kdYKmu6mZ4SN1gqa5qZXhI3WCprmrlPg+pGyzVVa3c8pC6wVJd1cpSXUlSMaetpI6wVFd1ctpK6gBLdVU3w0PqBkt1VSvDQ+oGS3VVK/d5SN1gqa5q5ZaH1A2W6qpWlupKkoo5bSV1hKW6qpPTVlIHWKqruhkeUjdYqqtaGR5SN1iqq1q5z0PqBkt1VSu3PKRusFRXtbJUV5JUzC0PqeMi4tSm+7CSuj6+tjI8pO77aNMdWGFdH18rOW0ldUhETAHHVg9nMnOuyf6MWtfHN04MD6kDIuIE4A+AU4HvVYuPBu4H3p2ZjzbVt1Ho+vjGkdNWUjd8BvgUMJWZGzNzIzAF/DFwS6M9G42uj2/suOUhdUBEfDszTyptGxddH9848iBBqRuejogLgM9m5gJAREwAvw4802jPRqPr4xs7hofUDRcDW4AbI+KJatkxwPaqbdx1fXxjx2krqUOq8z8trUaabbI/o9b18Y0Tw0OSVMxqK0lSMcNDklTM8JAkFTM8JEnF/j/hJ+dHAt3YPQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_data['label_current_charge'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data massaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_data(_df):\n",
    "    df=_df\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "def feature_eng(_df):\n",
    "    df=_df\n",
    "    df['avg_CC_1hop'] = df['sum_1hop_current_charge']/df['size_1hop']\n",
    "    df['avg_CC_2hop'] = df['sum_2hop_current_charge']/df['size_2hop']\n",
    "    df['avg_CC_3hop'] = df['sum_3hop_current_charge']/df['size_3hop']\n",
    "    df['avg_EF_1hop'] = df['sum_1hop_energy_fraction']/df['size_1hop']\n",
    "    df['avg_EF_2hop'] = df['sum_2hop_energy_fraction']/df['size_2hop']\n",
    "    df['avg_EF_3hop'] = df['sum_3hop_energy_fraction']/df['size_3hop']\n",
    "    df = df.drop([\n",
    "        'sum_1hop_current_charge', \n",
    "        'sum_2hop_current_charge', \n",
    "        'sum_3hop_current_charge',\n",
    "        'sum_1hop_energy_fraction',\n",
    "        'sum_2hop_energy_fraction',\n",
    "        'sum_3hop_energy_fraction',\n",
    "        'sum_1hop_flow_counter',\n",
    "        'sum_2hop_flow_counter',\n",
    "        'sum_3hop_flow_counter',\n",
    "        'sum_1hop_initial_charge',\n",
    "        'sum_2hop_initial_charge',\n",
    "        'sum_3hop_initial_charge'\n",
    "    ], axis='columns')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data\n",
    "X_val = val_data\n",
    "\n",
    "X_train = feature_eng(X_train)\n",
    "X_val = feature_eng(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(X_train['label_energy_fraction'].values)\n",
    "X_train = X_train.drop(['label_current_charge', 'label_energy_fraction', 'label_flow_count', 'label_initial_charge'], axis='columns')\n",
    "\n",
    "y_val = to_categorical(X_val['label_energy_fraction'].values)\n",
    "X_val = X_val.drop(['label_current_charge', 'label_energy_fraction', 'label_flow_count', 'label_initial_charge'], axis='columns')\n",
    "\n",
    "le = LabelEncoder()\n",
    "X_train['frame_type'] = le.fit_transform(X_train['frame_type'])\n",
    "X_val['frame_type'] = le.fit_transform(X_val['frame_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_size</th>\n",
       "      <th>frame_type</th>\n",
       "      <th>size_1hop</th>\n",
       "      <th>size_2hop</th>\n",
       "      <th>size_3hop</th>\n",
       "      <th>avg_CC_1hop</th>\n",
       "      <th>avg_CC_2hop</th>\n",
       "      <th>avg_CC_3hop</th>\n",
       "      <th>avg_EF_1hop</th>\n",
       "      <th>avg_EF_2hop</th>\n",
       "      <th>avg_EF_3hop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>534.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>534.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>534.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>534.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>534.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>534.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>534.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>534.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>534.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>534.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>534.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1542.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>99.995728</td>\n",
       "      <td>99.996440</td>\n",
       "      <td>99.996796</td>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1542.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>99.996440</td>\n",
       "      <td>99.996796</td>\n",
       "      <td>99.997010</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1542.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>99.996796</td>\n",
       "      <td>99.996440</td>\n",
       "      <td>99.997152</td>\n",
       "      <td>0.999968</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>0.999972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    frame_size  frame_type  size_1hop  size_2hop  size_3hop  avg_CC_1hop  \\\n",
       "0        534.0           1        2.0        3.0        4.0   100.000000   \n",
       "1        534.0           1        3.0        4.0        5.0   100.000000   \n",
       "2        534.0           1        3.0        5.0        6.0   100.000000   \n",
       "3        534.0           1        3.0        5.0        7.0   100.000000   \n",
       "4        534.0           1        3.0        5.0        6.0   100.000000   \n",
       "5        534.0           1        3.0        4.0        5.0   100.000000   \n",
       "6        534.0           1        2.0        3.0        4.0   100.000000   \n",
       "7        534.0           1        3.0        4.0        5.0   100.000000   \n",
       "8        534.0           1        3.0        5.0        6.0   100.000000   \n",
       "9        534.0           1        3.0        5.0        7.0   100.000000   \n",
       "10       534.0           1        3.0        5.0        6.0   100.000000   \n",
       "11       534.0           1        3.0        4.0        5.0   100.000000   \n",
       "12      1542.0           2        2.0        3.0        4.0    99.995728   \n",
       "13      1542.0           2        3.0        4.0        5.0    99.996440   \n",
       "14      1542.0           2        4.0        6.0        6.0    99.996796   \n",
       "\n",
       "    avg_CC_2hop  avg_CC_3hop  avg_EF_1hop  avg_EF_2hop  avg_EF_3hop  \n",
       "0    100.000000   100.000000     1.000000     1.000000     1.000000  \n",
       "1    100.000000   100.000000     1.000000     1.000000     1.000000  \n",
       "2    100.000000   100.000000     1.000000     1.000000     1.000000  \n",
       "3    100.000000   100.000000     1.000000     1.000000     1.000000  \n",
       "4    100.000000   100.000000     1.000000     1.000000     1.000000  \n",
       "5    100.000000   100.000000     1.000000     1.000000     1.000000  \n",
       "6    100.000000   100.000000     1.000000     1.000000     1.000000  \n",
       "7    100.000000   100.000000     1.000000     1.000000     1.000000  \n",
       "8    100.000000   100.000000     1.000000     1.000000     1.000000  \n",
       "9    100.000000   100.000000     1.000000     1.000000     1.000000  \n",
       "10   100.000000   100.000000     1.000000     1.000000     1.000000  \n",
       "11   100.000000   100.000000     1.000000     1.000000     1.000000  \n",
       "12    99.996440    99.996796     0.999957     0.999964     0.999968  \n",
       "13    99.996796    99.997010     0.999964     0.999968     0.999970  \n",
       "14    99.996440    99.997152     0.999968     0.999964     0.999972  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0d0b681f98>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEBCAYAAAB/rs7oAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEZhJREFUeJzt3X+M5HV9x/Hn7h5aym2UbkcrP45TOd+lSER+RLFi08afpFdplSJRoD+0gAbSVNLGNkVCAr3AmaaIBsPFFs6GpLT2UEO0+gdWtCSgXgRN314VuBNQ1z2qd7ZyuLv9Y74Lw3Z2Z+bmOzsz+3k+ksvNfD+f73ff7/nOvPa735357sTi4iKSpHJMDrsASdLaMvglqTAGvyQVxuCXpMIY/JJUGINfkgpj8EtSYQx+SSqMwS9JhTH4JakwBr8kFWbDsAuoPBc4E3gcmB9yLZI0LqaAFwH3AU92u9KoBP+ZwJeGXYQkjamzgXu6nTwqwf84wBNP/JSFhfZXC52Z2cjc3ME1LWoQ7GO02MdosY/eTE5OcPTRR0GVod0aleCfB1hYWFwx+JfG1wP7GC32MVrs47D0dIrcX+5KUmEMfkkqjMEvSYUx+CWpMF39cjcidgEvBhaAg8Dlmbl72Zwp4EbgzcAisC0zd9RbriSpX90e8V+cma/IzFcC24GPt5nzTuBEYAtwFnB1RGyupUpJUm26Cv7M/HHL3efRPPJf7nzglsxcyMxZYBdwXv8lSpLq1PX7+CNiB/BGYILm6ZzlNgGPtNzfCxzfSzEzMxtXHW80pnvZ3Mga9z4OPdV8y/Ba93HoqXmec8RU7dsd9/2xxD5Gyyj30XXwZ+a7ASLiQuAG4Jy6i5mbO7jihx4ajWlmZw/U/SXX3Hroo9GYZuv771zzr/vpD7219sduPewPsI9Rs1Z9TE5OdDxgbrterytk5k7gNyNiZtnQXuCElvubgH09VyRJGqiOR/wRsRE4OjP3Vfe3Avurf63uAN4TEZ8EZoBzaV44SJI0Qro51XMUcEdEHEXzehD7ga2ZuRgRdwFXZeb9wE7gVcCear1rMvOhQRQtSTp8HYM/M38AvHqFsXNabs8Dl9VXmiRpEPzkriQVxuCXpMIY/JJUGINfkgpj8EtSYQx+SSqMwS9JhTH4JakwBr8kFcbgl6TCGPySVBiDX5IKY/BLUmEMfkkqjMEvSYUx+CWpMAa/JBXG4Jekwhj8klQYg1+SCmPwS1JhDH5JKozBL0mFMfglqTAGvyQVZkOnCRExA+wEXgocAvYAl2Tm7LJ5/wC8HvhRteiOzLy21molSX3rGPzAInB9Zt4NEBE3ANuAP24zd1tm3lRfeZKkunUM/szcD9zdsuhe4LJBFSRJGqyezvFHxCTN0P/UClP+LCIeiIhdEXFS39VJkmrXzameVh8GDgLtTuf8FfB4Zi5ExEXAZyPiJZk53+3GZ2Y2rjreaEz3UuvIWi99DMMgHrv1sj/sY7SMch9dB39EbAe2AFszc2H5eGY+2nL7toj4W+A44JFuv8bc3EEWFhbbjjUa08zOHuh2UyNrPfQxzCd03Y/detgfYB+jZq36mJyc6HjA3Ha9biZFxHXA6cC5mfnkCnOObbn9JmAeeLTdXEnS8HTzds6TgQ8A3wa+EhEAD2Xm70bEbuCczHwMuDUiXggsAD8Bficzfz640iVJh6Obd/V8E5hYYezUltuvr7EuSdKA+MldSSqMwS9JhTH4JakwBr8kFcbgl6TCGPySVBiDX5IKY/BLUmEMfkkqjMEvSYUx+CWpMAa/JBXG4Jekwhj8klQYg1+SCmPwS1JhDH5JKozBL0mFMfglqTAGvyQVxuCXpMIY/JJUGINfkgpj8EtSYQx+SSqMwS9JhdnQaUJEzAA7gZcCh4A9wCWZObts3i8Cfw+cDvwcuDIzP1N7xZKkvnRzxL8IXJ+ZkZmnAN8BtrWZdyXwk8w8EdgK7IiIjfWVKkmqQ8fgz8z9mXl3y6J7gRPaTD0f+Fi1zh7gfuAtNdQoSapRx1M9rSJiErgM+FSb4U3AIy339wLH97L9mZnVf0BoNKZ72dzIWi99DMMgHrv1sj/sY7SMch89BT/wYeAgcNMAamFu7iALC4ttxxqNaWZnDwziy66p9dDHMJ/QdT9262F/gH2MmrXqY3JyouMBc9v1up0YEduBLcD5mbnQZspenn0KaBOwr+eKJEkD1VXwR8R1NN+tc25mPrnCtDuAS6r5W4Azgc/WUaQkqT4dgz8iTgY+ABwDfCUidkfEv1ZjuyPimGrqDcDzI+K/gM8Af5KZ4/8zmyStMx3P8WfmN4GJFcZObbn9U+C8+kqTJA2Cn9yVpMIY/JJUGINfkgpj8EtSYQx+SSqMwS9JhTH4JakwBr8kFcbgl6TCGPySVBiDX5IKY/BLUmEMfkkqjMEvSYUx+CWpMAa/JBXG4Jekwhj8klQYg1+SCmPwS1JhDH5JKozBL0mFMfglqTAGvyQVxuCXpMJs6GZSRGwH3gZsBk7JzAfbzLkaeC/wWLXoy5n5vnrKlCTVpavgB3YBfwd8qcO82zLzyv5KkiQNUlfBn5n3AETEYKuRJA1ct0f83XpHRLwR+D7wwcz8j5q3L0nqU53BfzNwbWY+FRFvAO6MiJMyc67bDczMbFx1vNGY7rPE0bBe+hiGQTx262V/2MdoGeU+agv+zPx+y+3PR8Q+4OXAF7vdxtzcQRYWFtuONRrTzM4e6LvOYVsPfQzzCV33Y7ce9gfYx6hZqz4mJyc6HjC3Xa+uAiLi2Jbbp9J8B1DWtX1JUj26fTvnjcDvAb8CfCEi5jLz5Ii4C7gqM+8HrouI04F54BBwYetPAZKk0dDtu3quAK5os/ycltsX11iXJGlA/OSuJBXG4Jekwhj8klQYg1+SCmPwS1JhDH5JKozBL0mFMfglqTAGvyQVxuCXpMIY/JJUGINfkgpj8EtSYQx+SSqMwS9JhTH4JakwBr8kFcbgl6TCGPySVBiDX5IKY/BLUmEMfkkqjMEvSYUx+CWpMAa/JBXG4JekwmzoNCEitgNvAzYDp2Tmg23mTAE3Am8GFoFtmbmj3lIlSXXo5oh/F/A64JFV5rwTOBHYApwFXB0Rm/uuTpJUu47Bn5n3ZOa+DtPOB27JzIXMnKX5zeK8OgqUJNWr46meLm3i2T8R7AWO73UjMzMbVx1vNKbbLj/01DzPOWKq1y9Xi8P52iv1odUdemp+II9dp20O8/nVi/XyvBpWH3Xv5176WOvnWF3BX4u5uYMsLCy2HWs0ppmdPbDi2Nb33znI0lb06Q+9dcW62lmtj3ExrBfmc46YGsp+7nUfD8N6eF7BcPsYpxxZMjk50fGAue16Pa/R3l7ghJb7m4BOp4ckSUNQ1xH/HcB7IuKTwAxwLnB2TduWJNWo4xF/RNwYEd8DjgO+EBHfrJbfFRFnVNN2At8F9gD3Atdk5kMDqlmS1IeOR/yZeQVwRZvl57Tcngcuq7c0SdIg+MldSSqMwS9JhTH4JakwBr8kFcbgl6TCGPySVBiDX5IKY/BLUmEMfkkqjMEvSYUx+CWpMAa/JBXG4Jekwhj8klQYg1+SCmPwS1JhDH5JKozBL0mFMfglqTAGvyQVxuCXpMIY/JJUGINfkgpj8EtSYQx+SSrMhm4mRcTLgFuBGWAOuCgz9yybczXwXuCxatGXM/N99ZUqSapDV8EP3Ax8JDM/ERHvAj4G/Fabebdl5pW1VSdJql3HUz0R8QLgNOD2atHtwGkR0RhkYZKkwejmHP/xwKOZOQ9Q/f9YtXy5d0TENyLi3yLirBrrlCTVpNtTPd24Gbg2M5+KiDcAd0bESZk51+0GZmY2rjreaEz3WeJg9FrXqPahlY3DPhuHGruxXvro1Vr23U3w7wOOjYipzJyPiCngmGr50zLz+y23Px8R+4CXA1/stpi5uYMsLCy2HWs0ppmdPbDi2DCtVFc7q/UxLob9eA/DqO+z9fC8guH2Mezn9eH0PTk50fGAue16nSZk5g+B3cAF1aILgK9n5mzrvIg4tuX2qcBmIHuuSJI0UN2e6rkUuDUirgKeAC4CiIi7gKsy837guog4HZgHDgEXtv4UIEkaDV0Ff2b+J/CqNsvPabl9cY11SZIGxE/uSlJhDH5JKozBL0mFMfglqTAGvyQVxuCXpMIY/JJUGINfkgpj8EtSYQx+SSqMwS9JhTH4JakwBr8kFcbgl6TCGPySVBiDX5IKY/BLUmEMfkkqjMEvSYUx+CWpMAa/JBXG4Jekwhj8klQYg1+SCmPwS1JhDH5JKsyGbiZFxMuAW4EZYA64KDP3LJszBdwIvBlYBLZl5o56y5Uk9avbI/6bgY9k5suAjwAfazPnncCJwBbgLODqiNhcR5GSpPp0POKPiBcApwFvqBbdDtwUEY3MnG2Zej5wS2YuALMRsQs4D7ihizqmACYnJ1adtNr4C44+sosvMxid6u53/iga1uM9rK87DvtsHGrsxjD7GKccWbbOVC/rTSwuLq46ISJOB27LzJNbln0LeFdmfq1l2QPAH2XmfdX9PweOy8wruqjjtcCXeilckvS0s4F7up3c1Tn+NXAfzcIfB+aHXIskjYsp4EU0M7Rr3QT/PuDYiJjKzPnql7jHVMtb7QVOaClgE/BIl3U8SQ/frSRJT/tOryt0/OVuZv4Q2A1cUC26APj6svP7AHcA74mIyYhoAOcC/9xrQZKkwer2XT2XApdHxLeBy6v7RMRdEXFGNWcn8F1gD3AvcE1mPlRzvZKkPnX85a4kaX3xk7uSVBiDX5IKY/BLUmEMfkkqzJp8gCsiZmi+6+elwCGa7/y5JDNnI2IReABYqKZfmJkPVOttpXnJhw3AV4E/zMz/6Weshl52AS+u6j0IXJ6Zu1e7kN0gxgbYx8PAz6p/AH+RmZ+r1nk1zes0HQk8TPPT2z/sZ6wuEfFB4GrglMx8cBC1DqmPsXp9VNt/mDbPoXHbJ6v0MXb7ZLm1OuJfBK7PzMjMU2h+4GBby/hrMvPU6t/SA7gRuAXYmpknAgeAK/sZq8nFmfmKzHwlsB34eLV8tQvZDWJsUH0AvL1lfyyF/iTwCeB9VT3/TrUPD3esLhFxGvBqqg8MDqLWYfTRYpxeH0ue9Rwa132yvI+W5eO4T562JsGfmfsz8+6WRffS/JTvat4C3N9yhHszzQvB9TPWt8z8ccvd5wELLReyu71afjtwWkQ0BjE2qD46rHI68LPMXPqE9c3A7/c51reIeC7Nb4qXDbjWYfSxmpF8faxi7PbJYRibfbLm5/ir79KXAZ9qWXx3ROyOiL+pXgDw/y/5sBc4vs+xWkTEjojYC1wLXFxt/9HMnAeo/n+sWj6IsUH1seQfI+IbEfHRiHh+texZj2tm/giYjIhf6mOsDtcAn8jMh1uWDaLWYfSxZKxeH5Xlz6Fx3Cft+lgyjvvkacP45e6HaZ5Tvqm6vykzzwBeB/wa8NdDqKknmfnuzNwE/CXdXXZ6JK3Qx9mZ+QrgTGCCZ/bTyImIs4AzgI8Ou5Z+dOhj7F4fjNFzqIOV+hjHffIsaxr8EbGd5h9qOT+b1+0nM/dV//8E2AH8ejV96aJvSzbxzIXhDnesVpm5E/hN4HtUF7KDp/8a2dKF7PYNYGwgfUTETMv+eJJmELXdHxHxy8BCZu7vY6xfvwGcBDxU/SLuOOBzNP8gUN21rnkfEfHGcXx9rPAcGsTjPsh9slIfY51ZS9Ys+CPiOprn5M6tHkgi4uiIOLK6vQF4O80LwgF8FjgzIrZU9y8F/qnPsX572BgRx7fc3wrsB1a8kF2ucpG7wx0bYB8/i4jnVcsmgHfwzP74KnBkRLy2un8pzQvz9TPWl8zclpnHZObmzNxM8xvwm2j+9FJ3rcPo475xen1UdR61wnNoEI/7wPbJSn2MW2atZE2u1RMRJwMPAt8G/rda/BBwPc13qiwCRwBfAf40Mw9W6721mjMFfB34g8z8aT9jffbxQuBO4CiafzdgP3BlZn4tIn6V5lsvjwaeoPnWy6zWq31sEH0A/w38C83HbQr4FnBFZj5erfcamvvrF3jmrXM/6GesTtXR8m9n822Qtde61n0A04zR66Pa9ktY4Tk0TvtkpT6AzYzZPmnHi7RJUmH85K4kFcbgl6TCGPySVBiDX5IKY/BLUmEMfkkqjMEvSYUx+CWpMP8HtyFZNN8psiAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data['label_energy_fraction'].value_counts().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((232028, 11), (232028, 1)), ((66503, 11), (66503, 1)))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape, y_train.shape), (X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "\n",
    "# Returns a short sequential model\n",
    "def create_model(sample_input): # numpy array so we can use .shape\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Dense(64, activation='softmax', input_shape=sample_input.shape),\n",
    "        layers.Dense(64, activation='softmax'),\n",
    "        layers.Dense(6, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # from my initial tests\n",
    "    model.compile(optimizer=tf.train.RMSPropOptimizer(0.01),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    # from another tf.keras tutorial\n",
    "#     model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "#                 loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "#                 metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 HOPS Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(os.path.join(logdir,'3hops'), histogram_freq=1)\n",
    "chk_callback = tf.keras.callbacks.ModelCheckpoint(os.path.join(chk_base_dir,'3hops'), \n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                768       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 5,318\n",
      "Trainable params: 5,318\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(X_train.values[0])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 232028 samples, validate on 66503 samples\n",
      "Epoch 1/100\n",
      "231936/232028 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 1.0000\n",
      "Epoch 00001: saving model to ./checkpoints/3hops\n",
      "WARNING:tensorflow:From /home/pregis/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py:1436: update_checkpoint_state (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.train.CheckpointManager to manage checkpoints rather than manually editing the Checkpoint proto.\n",
      "232028/232028 [==============================] - 9s 41us/sample - loss: 0.0334 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      "231840/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00002: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      "231968/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00003: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      "231712/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00004: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      "231232/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00005: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      "231488/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00006: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      "230688/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00007: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      "231424/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00008: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      "231616/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00009: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      "230368/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00010: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 39us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      "231296/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00011: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "231808/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000-\n",
      "Epoch 00012: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      "230272/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00013: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      "230112/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00014: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      "231840/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00015: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      "231104/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00016: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      "231616/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00017: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      "231808/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00018: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "230496/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00019: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      "230304/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00020: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 34us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      "231904/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00021: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 34us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      "231040/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00022: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "230944/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00023: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "229952/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00024: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "230304/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00025: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      "230336/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00026: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      "231616/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00027: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "231040/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00028: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 34us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      "230048/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00029: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      "231712/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00030: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "231776/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00031: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      "231008/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00032: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 34us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      "230880/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00033: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "230816/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00034: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      "230528/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00035: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      "231648/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00036: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "230560/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00037: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      "231712/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00038: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "230656/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00039: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 34us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "230880/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00040: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      "230208/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00041: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "231104/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00042: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "231072/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00043: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "230720/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00044: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "231008/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00045: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "230464/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00046: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "230784/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00047: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "231296/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00048: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "231264/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00049: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "230720/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00050: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "230784/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00051: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "230400/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00052: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "230400/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00053: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "230336/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00054: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "231936/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00055: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231712/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00056: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "231904/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00057: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "231360/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00058: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "230720/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00059: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 34us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "231744/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00060: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "231040/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00061: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "231872/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00062: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "230592/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00063: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 39us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "230912/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00064: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "231744/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00065: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "230144/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00066: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "231680/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00067: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "231072/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00068: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "231360/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00069: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "232000/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00070: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "231968/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00071: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "230624/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00072: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "231936/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00073: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 40us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "230880/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00074: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "230688/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00075: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "231392/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00076: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "230720/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00077: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "230208/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00078: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "231168/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00079: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "232000/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00080: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "231264/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00081: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "231648/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00082: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "230208/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00083: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230176/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00084: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "230688/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00085: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "231712/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00086: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "231936/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00087: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "231744/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00088: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "231520/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00089: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "230528/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00090: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "231616/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00091: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "230848/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00092: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "232000/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00093: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "231456/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00094: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "230752/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00095: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "231968/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00096: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "230752/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00097: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 39us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "231168/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00098: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "231392/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00099: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "231648/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00100: saving model to ./checkpoints/3hops\n",
      "232028/232028 [==============================] - 9s 39us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0d000d3b00>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=X_train.values,\n",
    "    y=y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_val.values, y_val),\n",
    "    callbacks = [tensorboard_callback, chk_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 HOPS Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(os.path.join(logdir,'2hops'), histogram_freq=1)\n",
    "chk_callback = tf.keras.callbacks.ModelCheckpoint(os.path.join(chk_base_dir,'2hops'), \n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['size_3hop', 'avg_CC_3hop', 'avg_EF_3hop'], axis='columns')\n",
    "X_val = X_val.drop(['size_3hop', 'avg_CC_3hop', 'avg_EF_3hop'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                576       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 5,126\n",
      "Trainable params: 5,126\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(X_train.values[0])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 232028 samples, validate on 66503 samples\n",
      "Epoch 1/100\n",
      "230688/232028 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9989\n",
      "Epoch 00001: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 0.0338 - acc: 0.9989 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      "230400/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00002: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      "231328/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00003: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      "231616/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00004: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      "231552/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00005: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      "231520/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00006: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      "230528/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00007: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      "230240/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00008: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      "230816/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00009: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      "230400/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00010: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      "231808/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00011: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 34us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "231936/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00012: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      "230752/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00013: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      "231264/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00014: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      "231744/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00015: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      "232000/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00016: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      "231232/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00017: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      "231584/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00018: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 34us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "231712/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00019: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      "230784/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00020: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      "231200/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00021: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      "231872/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00022: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 34us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "231008/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00023: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "231072/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00024: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "231328/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00025: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      "230720/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00026: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      "230784/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00027: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      "230720/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00028: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231712/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00029: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 34us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      "231040/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00030: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "230464/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00031: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      "230560/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00032: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      "231072/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00033: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 39us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "231328/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00034: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      "230752/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00035: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      "231360/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00036: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 39us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "230880/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00037: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      "231072/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00038: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "231008/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00039: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "231584/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000- ETA: 1s - lo\n",
      "Epoch 00040: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      "230848/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00041: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 34us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "231904/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00042: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "230688/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00043: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "231008/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00044: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "231424/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00045: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "230400/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00046: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "231968/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00047: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "230592/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00048: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "230752/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00049: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "231456/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00050: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "230848/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00051: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "230144/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00052: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "231808/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00053: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "230592/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00054: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "231392/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00055: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "230848/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00056: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231584/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00057: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "231168/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00058: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "231040/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00059: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "230944/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00060: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "231584/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00061: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "231296/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00062: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "231136/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00063: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "231488/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00064: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "231296/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00065: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "231424/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00066: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "230816/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00067: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "230272/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00068: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "231808/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00069: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "230944/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00070: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "230528/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00071: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "231456/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00072: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "231648/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00073: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "230368/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00074: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "230688/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00075: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "231232/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00076: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "231520/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00077: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 39us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "230560/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00078: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "231520/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00079: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "231552/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00080: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "230624/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00081: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "231584/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00082: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "231904/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00083: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 39us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "231712/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00084: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231968/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00085: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "231008/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00086: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "231744/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00087: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "230304/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00088: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "231648/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00089: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "231008/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00090: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "231232/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00091: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "230336/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00092: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "231168/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00093: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "231872/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00094: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "231488/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00095: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "231136/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00096: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 40us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "231232/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00097: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "230304/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00098: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 34us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "231360/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00099: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 9s 39us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "230752/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00100: saving model to ./checkpoints/2hops\n",
      "232028/232028 [==============================] - 8s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0d0b51e978>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=X_train.values,\n",
    "    y=y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_val.values, y_val),\n",
    "    callbacks = [tensorboard_callback, chk_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 HOP Neighborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(os.path.join(logdir,'1hop'), histogram_freq=1)\n",
    "chk_callback = tf.keras.callbacks.ModelCheckpoint(os.path.join(chk_base_dir,'1hop'), \n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(['size_2hop', 'avg_CC_2hop', 'avg_EF_2hop'], axis='columns')\n",
    "X_val = X_val.drop(['size_2hop', 'avg_CC_2hop', 'avg_EF_2hop'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                384       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 4,934\n",
      "Trainable params: 4,934\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(X_train.values[0])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 232028 samples, validate on 66503 samples\n",
      "Epoch 1/100\n",
      "231648/232028 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9990\n",
      "Epoch 00001: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 0.0335 - acc: 0.9990 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      "230624/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00002: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      "230976/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00003: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      "230560/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00004: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      "231168/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00005: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      "230464/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00006: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      "231744/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00007: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      "230496/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00008: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      "231200/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00009: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      "230560/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00010: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 11/100\n",
      "231904/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00011: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 39us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "230464/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00012: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      "231104/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00013: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      "231328/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00014: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      "231072/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00015: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 16/100\n",
      "231392/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00016: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 17/100\n",
      "230880/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00017: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      "231616/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00018: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "230944/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00019: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      "230336/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00020: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      "231680/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00021: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      "231936/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00022: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 23/100\n",
      "231264/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00023: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "232000/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00024: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "231456/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00025: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      "231584/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00026: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 27/100\n",
      "231040/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00027: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      "230880/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00028: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231936/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00029: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      "231040/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00030: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "231808/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00031: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      "230560/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00032: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      "231872/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00033: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "230592/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00034: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      "230592/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00035: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      "231712/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00036: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "230208/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00037: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 39us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      "230944/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00038: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "231552/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00039: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "231552/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00040: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 41/100\n",
      "230720/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00041: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 42/100\n",
      "230528/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00042: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 43/100\n",
      "231872/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00043: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "231168/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00044: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 45/100\n",
      "231712/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00045: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "231776/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00046: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "230880/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00047: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "230592/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00048: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "230848/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00049: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "230496/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00050: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "231648/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00051: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "231136/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00052: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "232000/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00053: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "231840/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00054: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "230560/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00055: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "231072/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00056: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 35us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "230624/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00057: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 40us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "231616/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00058: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 59/100\n",
      "230144/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00059: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "231072/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00060: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 39us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "230592/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00061: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "230496/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00062: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 39us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "230560/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00063: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "231872/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00064: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "230976/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00065: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 39us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "231744/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00066: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "231424/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00067: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "231712/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00068: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 40us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "231104/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00069: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "230976/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00070: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "231776/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00071: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 41us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "230688/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00072: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 73/100\n",
      "230912/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00073: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 39us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "230944/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00074: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 75/100\n",
      "232000/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00075: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "231616/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00076: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 40us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "231616/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00077: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 78/100\n",
      "231904/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00078: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 39us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "230720/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00079: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "231584/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00080: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "231424/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00081: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "230624/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00082: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "231200/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00083: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "231328/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00084: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "231840/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00085: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232000/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00086: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 87/100\n",
      "231744/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00087: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 40us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 88/100\n",
      "231232/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00088: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "231456/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00089: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 39us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "230752/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00090: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "231360/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00091: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "231104/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00092: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 40us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "232000/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00093: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 39us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 94/100\n",
      "232000/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00094: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 36us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "230592/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00095: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 40us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "230784/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00096: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "231392/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00097: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 39us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 98/100\n",
      "231488/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00098: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 38us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "231424/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00099: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 8s 37us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "231584/232028 [============================>.] - ETA: 0s - loss: 5.9605e-07 - acc: 1.0000\n",
      "Epoch 00100: saving model to ./checkpoints/1hop\n",
      "232028/232028 [==============================] - 9s 40us/sample - loss: 5.9605e-07 - acc: 1.0000 - val_loss: 5.9605e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0d005dbd30>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=X_train.values,\n",
    "    y=y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_val.values, y_val),\n",
    "    callbacks = [tensorboard_callback, chk_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
